{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "273bc2d5-d056-4be6-8504-adaf664e1d0d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "\n",
    "### 1. MSR-VTT (Microsoft Research Video to Text)\n",
    "[HuggingFace](https://huggingface.co/datasets/friedrichor/MSR-VTT)\n",
    "\n",
    "Большой датасет с разнообразными видео из 20 категорий. Можно взять за основу. Описания видео кратко сформулорованы, в трейн часте много разных фариантов описаний каждого видео (перефразировки). Длительность клипов 10–30 c\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"video_id\": \"video0\",\n",
    "  \"video\": \"video0.mp4\",\n",
    "  \"category_map\": {\n",
    "    \"0\": \"music\",\n",
    "    \"1\": \"people\",\n",
    "    \"2\": \"gaming\",\n",
    "    \"3\": \"sports\",\n",
    "    \"4\": \"news\",\n",
    "    \"5\": \"education\",\n",
    "    \"6\": \"TV shows\",\n",
    "    \"7\": \"movie\",\n",
    "    \"8\": \"animation\",\n",
    "    \"9\": \"vehicles\",\n",
    "    \"10\": \"travel\",\n",
    "    \"11\": \"science\",\n",
    "    \"12\": \"animals\",\n",
    "    \"13\": \"kids\",\n",
    "    \"14\": \"food\",\n",
    "    \"15\": \"cooking\",\n",
    "    \"16\": \"beauty\",\n",
    "    \"17\": \"fashion\",\n",
    "    \"18\": \"documentary\",\n",
    "    \"19\": \"ads\"\n",
    "  }\n",
    "  \"url\": \"https://www.youtube.com/watch?v=...\",\n",
    "  \"start_time\": 10.0,\n",
    "  \"end_time\": 30.0,\n",
    "  \"caption\": \"a girl is playing a guitar\",\n",
    "  \"sen_id\": 1500\n",
    "}\n",
    "```\n",
    "\n",
    "Train:\n",
    "* train_7k: 7,010 videos, 140,200 captions\n",
    "* train_9k: 9,000 videos, 180,000 captions\n",
    "\n",
    "Test:\n",
    "* test_1k: 1,000 videos, 1,000 captions\n",
    "\n",
    "***\n",
    "\n",
    "### 2. VATEX (In-the-Wild Multilingual)\n",
    "Чистая версия: [HuggingFace](https://huggingface.co/datasets/VLM2Vec/VATEX). Оригинальная версия: [HuggingFace](https://huggingface.co/datasets/HuggingFaceM4/vatex)\n",
    "\n",
    "Все видео про людей (Human Actions). Каждый элемент содержит 10 описаний (в оригинальном варианте есть английские и китайские варианты описаний).\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"videoID\": \"V_001\",\n",
    "  \"enCap\": [\n",
    "    \"A person is doing pushups on a floor with good form...\",\n",
    "    \"Man exercising in a gym doing pushups...\",\n",
    "    ...\n",
    "  ],\n",
    "}\n",
    "```\n",
    "\n",
    "* test: 4,480 videos\n",
    "\n",
    "***\n",
    "\n",
    "### 3. YouCook2 (Instructional / Procedural)\n",
    "[HuggingFace](https://huggingface.co/datasets/lmms-lab/YouCook2)\n",
    "\n",
    "Видео про кулинарию, но можно взять небольшую часть. Некоторые видео слишком длинные, берем только короткие. Только один вариант описения\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"id\": \"xHr8X2Wpmno_0\",\n",
    "  \"video_url\": \"https://www.youtube.com/watch?v=...\",\n",
    "  \"recipe_type\": 266,\n",
    "  \"segment\": [47, 60],\n",
    "  \"sentence\": \"pick the ends off the verdalago\",\n",
    "  \"video_path\": \"val/xHr8X2Wpmno_0.mp4\",\n",
    "  \"youtube_id\": \"xHr8X2Wpmno\",\n",
    "}\n",
    "```\n",
    "\n",
    "* val: 3,180 videos\n",
    "* test: 1,470 videos\n",
    "\n",
    "***\n",
    "\n",
    "### Отклоненные датасеты\n",
    "\n",
    "1.  **ActivityNet Captions** [HuggingFace](https://huggingface.co/datasets/HuggingFaceM4/ActivitiyNet_Captions)\n",
    "    *   Слишком длинные видео.\n",
    "2.  **HowTo100M** [HuggingFace](https://huggingface.co/datasets/HuggingFaceM4/howto100m)\n",
    "    *   Подходит только для Pre-training. Данные слишком грязные\n",
    "3.  **DiDeMo** [HuggingFace](https://huggingface.co/datasets/friedrichor/DiDeMo)\n",
    "    *   Слишком длинные видео. \n",
    "4.  **Kinetics-400/600** [Kaggle](https://www.kaggle.com/datasets/rohanmallick/kinetics-train-5per)\n",
    "    *   500k видно, но без описания\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b144ec-1e23-4293-94cf-eb9d3d8bef06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: VATEX | Model: XCLIP\n",
      "\n",
      "--- Clustering Metrics ---\n",
      "Number of clusters: 10\n",
      "Supervised metrics:\n",
      "Unsupervised metrics:\n",
      "  Silhouette: 0.0062\n",
      "  Calinski-Harabasz: 12.2073\n",
      "  Davies-Bouldin: 5.3613\n",
      "\n",
      "Dataset: MSRVTT | Model: XCLIP\n",
      "\n",
      "--- Clustering Metrics ---\n",
      "Number of clusters: 20\n",
      "Supervised metrics:\n",
      "  ARI: 0.2034\n",
      "  NMI: 0.3818\n",
      "Unsupervised metrics:\n",
      "  Silhouette: 0.0302\n",
      "  Calinski-Harabasz: 12.0438\n",
      "  Davies-Bouldin: 4.0354\n",
      "\n",
      "Dataset: YOUCOOK2 | Model: XCLIP\n",
      "\n",
      "--- Clustering Metrics ---\n",
      "Number of clusters: 10\n",
      "Supervised metrics:\n",
      "Unsupervised metrics:\n",
      "  Silhouette: 0.0649\n",
      "  Calinski-Harabasz: 35.4584\n",
      "  Davies-Bouldin: 2.8071\n",
      "\n",
      "Dataset: VATEX | Model: SIGLIP\n",
      "\n",
      "--- Clustering Metrics ---\n",
      "Number of clusters: 10\n",
      "Supervised metrics:\n",
      "Unsupervised metrics:\n",
      "  Silhouette: 0.0387\n",
      "  Calinski-Harabasz: 22.1261\n",
      "  Davies-Bouldin: 3.6919\n",
      "\n",
      "Dataset: MSRVTT | Model: SIGLIP\n",
      "\n",
      "--- Clustering Metrics ---\n",
      "Number of clusters: 20\n",
      "Supervised metrics:\n",
      "  ARI: 0.2234\n",
      "  NMI: 0.4079\n",
      "Unsupervised metrics:\n",
      "  Silhouette: 0.0446\n",
      "  Calinski-Harabasz: 15.9338\n",
      "  Davies-Bouldin: 3.2328\n",
      "\n",
      "Dataset: YOUCOOK2 | Model: SIGLIP\n",
      "\n",
      "--- Clustering Metrics ---\n",
      "Number of clusters: 10\n",
      "Supervised metrics:\n",
      "Unsupervised metrics:\n",
      "  Silhouette: 0.0429\n",
      "  Calinski-Harabasz: 24.8892\n",
      "  Davies-Bouldin: 3.2743\n",
      "\n",
      "Dataset: VATEX | Model: QWEN3\n",
      "\n",
      "--- Clustering Metrics ---\n",
      "Number of clusters: 10\n",
      "Supervised metrics:\n",
      "Unsupervised metrics:\n",
      "  Silhouette: 0.0309\n",
      "  Calinski-Harabasz: 17.4434\n",
      "  Davies-Bouldin: 4.2778\n",
      "\n",
      "Dataset: MSRVTT | Model: QWEN3\n",
      "\n",
      "--- Clustering Metrics ---\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from src.data_loader import load_dataset_embeddings\n",
    "from src.clustering import evaluate_clustering\n",
    "from src.retrieval import evaluate_retrieval\n",
    "from src.visualization import compute_rank\n",
    "\n",
    "DIRS = {\n",
    "    \"xclip\": \"clip\",\n",
    "    \"siglip\": \"clip\",\n",
    "    \"qwen3\": \"vlm\",\n",
    "    \"videomae\": \"video-mae\"\n",
    "}\n",
    "\n",
    "DATASETS = [\"msrvtt\", \"vatex\", \"youcook2\"]\n",
    "\n",
    "\n",
    "EMBED_DIR = \"./embedings/\"\n",
    "VLM_DIR = EMBED_DIR + \"vlm/\"\n",
    "CLIP_DIR = EMBED_DIR + \"clip/\"\n",
    "MAE_DIR = EMBED_DIR + \"video-mae/\"\n",
    "embed_dir = CLIP_DIR\n",
    "dataset = \"msrvtt\"\n",
    "model = \"xclip\"\n",
    "\n",
    "def whatup(model, dataset):\n",
    "    embed_dir = EMBED_DIR + DIRS[model] + '/'\n",
    "    \n",
    "    video_embs, text_embs, categories, df = load_dataset_embeddings(embed_dir, dataset, model)\n",
    "    \n",
    "    # print(f\"Video embeddings: {video_embs.shape if video_embs is not None else None}\")\n",
    "    # print(f\"Text embeddings: {text_embs.shape if text_embs is not None else None}\")\n",
    "    \n",
    "    # print(f\"\\n{'='*60}\")\n",
    "    print(f\"Dataset: {dataset.upper()} | Model: {model.upper()}\")\n",
    "    # print('='*60)\n",
    "    \n",
    "    # print(\"\\n--- Embedding Space Analysis ---\")\n",
    "    # if video_embs is not None:\n",
    "    #     rank = compute_rank(video_embs)\n",
    "    #     print(f\"Matrix rank (video): {rank}/{video_embs.shape[1]}\")\n",
    "    # if text_embs is not None:\n",
    "    #     rank_text = compute_rank(text_embs)\n",
    "    #     print(f\"Matrix rank (text): {rank_text}/{text_embs.shape[1]}\")\n",
    "\n",
    "    print(\"\\n--- Clustering Metrics ---\")\n",
    "    if categories is not None:\n",
    "        metrics, n_clusters_used = evaluate_clustering(video_embs, categories, n_clusters=10)\n",
    "        print(f\"Number of clusters: {n_clusters_used}\")\n",
    "        print(\"Supervised metrics:\")\n",
    "        for metric in [\"ARI\", \"NMI\"]:\n",
    "            if metric in metrics:\n",
    "                print(f\"  {metric}: {metrics[metric]:.4f}\")\n",
    "        print(\"Unsupervised metrics:\")\n",
    "        for metric in [\"Silhouette\", \"Calinski-Harabasz\", \"Davies-Bouldin\"]:\n",
    "            if metric in metrics:\n",
    "                print(f\"  {metric}: {metrics[metric]:.4f}\")\n",
    "    else:\n",
    "        if n_clusters is None:\n",
    "            print(\"Warning: No ground truth labels. Specify --n_clusters for unsupervised evaluation.\")\n",
    "        else:\n",
    "            metrics, n_clusters_used = evaluate_clustering(video_embs, categories=None, \n",
    "                                                          n_clusters=n_clusters)\n",
    "            print(f\"Number of clusters: {n_clusters_used}\")\n",
    "            print(\"Unsupervised metrics:\")\n",
    "            for metric, value in metrics.items():\n",
    "                print(f\"  {metric}: {value:.4f}\")\n",
    "    print()\n",
    "\n",
    "for model in [\"xclip\", \"siglip\", \"qwen3\", \"videomae\"]:\n",
    "    for dataset in [\"vatex\", \"msrvtt\", \"youcook2\"]:\n",
    "        whatup(model, dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssl-baseline",
   "language": "python",
   "name": "ssl-baseline"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
