{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T20:42:52.114479Z",
     "iopub.status.busy": "2025-12-16T20:42:52.114267Z",
     "iopub.status.idle": "2025-12-16T20:44:35.229025Z",
     "shell.execute_reply": "2025-12-16T20:44:35.228315Z",
     "shell.execute_reply.started": "2025-12-16T20:42:52.114462Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install --upgrade \"pyarrow>=21.0.0\"\n",
    "# !pip install -q \"transformers>=4.57.0\"\n",
    "# !pip install -q datasets av\n",
    "# !pip install -q bitsandbytes accelerate\n",
    "# !pip install \"pydantic<2.12\" --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip freeze | grep pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install \"pydantic<2.12\" --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import av\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoModelForVision2Seq, AutoProcessor, BitsAndBytesConfig\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T20:45:11.080040Z",
     "iopub.status.busy": "2025-12-16T20:45:11.079442Z",
     "iopub.status.idle": "2025-12-16T20:45:12.280248Z",
     "shell.execute_reply": "2025-12-16T20:45:12.279444Z",
     "shell.execute_reply.started": "2025-12-16T20:45:11.080019Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import subprocess\n",
    "import os\n",
    "import zipfile\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from tqdm import tqdm\n",
    "import threading\n",
    "from datasets import load_dataset\n",
    "\n",
    "ZIP_PATH\n",
    "\n",
    "category_map = {\n",
    "    \"0\": \"music\",\n",
    "    \"1\": \"people\", \n",
    "    \"2\": \"gaming\",\n",
    "    \"3\": \"sports/actions\",\n",
    "    \"4\": \"news/events/politics\",\n",
    "    \"5\": \"education\",\n",
    "    \"6\": \"tv shows\",\n",
    "    \"7\": \"movie/comedy\", \n",
    "    \"8\": \"animation\",\n",
    "    \"9\": \"vehicles/autos\",\n",
    "    \"10\": \"howto\",\n",
    "    \"11\": \"travel\",\n",
    "    \"12\": \"science/technology\",\n",
    "    \"13\": \"animals/pets\",\n",
    "    \"14\": \"kids/family\",\n",
    "    \"15\": \"documentary\",\n",
    "    \"16\": \"food/drink\",\n",
    "    \"17\": \"cooking\",\n",
    "    \"18\": \"beauty/fashion\",\n",
    "    \"19\": \"advertisement\"\n",
    "}\n",
    "\n",
    "def download_msrvtt_zip():\n",
    "    zip_path = \"MSRVTT_Videos.zip\"\n",
    "    if not os.path.exists(zip_path):\n",
    "        url = \"https://huggingface.co/datasets/friedrichor/MSR-VTT/resolve/main/MSRVTT_Videos.zip\"\n",
    "        print(\"Скачиваю архив...\")\n",
    "        response = requests.get(url)\n",
    "        with open(zip_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "    return zip_path\n",
    "\n",
    "def extract_video(zip_ref, video_file, output_dir):\n",
    "    video_path = os.path.join(output_dir, video_file.split('/')[-1])\n",
    "    if os.path.exists(video_path):\n",
    "        return video_path\n",
    "    \n",
    "    try:\n",
    "        with zip_ref.open(f\"video/{video_file}\") as src, open(video_path, 'wb') as dst:\n",
    "            dst.write(src.read())\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "    return video_path\n",
    "\n",
    "def process_msrvtt_video(zip_ref, item, output_dir):\n",
    "    video_file = item['video']\n",
    "    duration = item['end time'] - item['start time']\n",
    "    \n",
    "    if duration > 30:\n",
    "        return None\n",
    "    \n",
    "    video_path = extract_video(zip_ref, video_file, output_dir)\n",
    "    if not video_path:\n",
    "        return None\n",
    "    \n",
    "    return {\n",
    "        'video_path': video_path,\n",
    "        'caption': item['caption'],\n",
    "        'category': category_map.get(str(item['category']), \"unknown\")\n",
    "    }\n",
    "\n",
    "def download_msrvtt_dataset(save_path, num_videos, max_workers=10):\n",
    "    dataset = load_dataset(\"friedrichor/MSR-VTT\", \"test_1k\", split=\"test\", streaming=True)\n",
    "    \n",
    "    items = []\n",
    "    for i, item in enumerate(dataset):\n",
    "        if item['end time'] - item['start time'] <= 30:\n",
    "            items.append(item)\n",
    "        if len(items) >= num_videos:\n",
    "            break\n",
    "    \n",
    "    print(f\"Найдено {len(items)} видео до 30 секунд\")\n",
    "    \n",
    "    zip_path = download_msrvtt_zip()\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    samples = []\n",
    "    lock = threading.Lock()\n",
    "    \n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref, ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(process_msrvtt_video, zip_ref, item, save_path): item for item in items}\n",
    "        \n",
    "        for future in tqdm(as_completed(futures), total=len(futures), desc=\"Извлечение\"):\n",
    "            result = future.result()\n",
    "            if result:\n",
    "                with lock:\n",
    "                    samples.append(result)\n",
    "    \n",
    "    df = pd.DataFrame(samples)\n",
    "    df.to_csv(os.path.join(save_path, \"msrvtt_dataset.csv\"), index=False)\n",
    "    print(f\"Обработано {len(df)} видео\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T20:54:29.936746Z",
     "iopub.status.busy": "2025-12-16T20:54:29.935870Z",
     "iopub.status.idle": "2025-12-16T20:54:29.940462Z",
     "shell.execute_reply": "2025-12-16T20:54:29.939750Z",
     "shell.execute_reply.started": "2025-12-16T20:54:29.936707Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20\n",
    "MAX_PIXELS = 298 * 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T20:54:35.705175Z",
     "iopub.status.busy": "2025-12-16T20:54:35.704347Z",
     "iopub.status.idle": "2025-12-16T20:54:35.717785Z",
     "shell.execute_reply": "2025-12-16T20:54:35.717141Z",
     "shell.execute_reply.started": "2025-12-16T20:54:35.705140Z"
    }
   },
   "outputs": [],
   "source": [
    "def sample_frames(video_path, num_frames=10):\n",
    "    container = av.open(video_path)\n",
    "    total_frames = container.streams.video[0].frames\n",
    "    if total_frames <= 0: return None\n",
    "    \n",
    "    indices = np.linspace(0, total_frames - 1, num_frames).astype(int)\n",
    "    frames = []\n",
    "    container.seek(0)\n",
    "    \n",
    "    for i, frame in enumerate(container.decode(video=0)):\n",
    "        if i in indices:\n",
    "            frames.append(frame.to_image())\n",
    "        if len(frames) == num_frames:\n",
    "            break\n",
    "    \n",
    "    while len(frames) < num_frames and len(frames) > 0:\n",
    "        frames.append(frames[-1])\n",
    "        \n",
    "    return frames\n",
    "\n",
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, dataframe, processor):\n",
    "        self.df = dataframe\n",
    "        self.processor = processor\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        video_path = row['video_path']\n",
    "        frames = sample_frames(video_path, num_frames=10)\n",
    "        if frames is None: return None\n",
    "            \n",
    "        conversation = [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"video\", \"video\": frames},\n",
    "                {\"type\": \"text\", \"text\": \"A very short, concise caption for this video.\"},\n",
    "            ],\n",
    "        }]\n",
    "        \n",
    "        prompt = self.processor.apply_chat_template(\n",
    "            conversation, tokenize=False, add_generation_prompt=True\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"frames\": frames, \n",
    "            \"prompt\": prompt,\n",
    "            \"video_path\": video_path\n",
    "        }\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return batch\n",
    "\n",
    "class CaptionGenerationPipeline:\n",
    "    def __init__(self):        \n",
    "        bnb_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_use_double_quant=True,\n",
    "            bnb_4bit_quant_type=\"nf4\",\n",
    "            bnb_4bit_compute_dtype=torch.bfloat16\n",
    "        )\n",
    "        \n",
    "        self.processor = AutoProcessor.from_pretrained(\n",
    "            \"Qwen/Qwen3-VL-2B-Instruct\",\n",
    "            max_pixels=MAX_PIXELS,\n",
    "        )\n",
    "        \n",
    "        self.model = AutoModelForVision2Seq.from_pretrained(\n",
    "            \"Qwen/Qwen3-VL-2B-Instruct\",\n",
    "            quantization_config=bnb_config,\n",
    "            device_map=\"cuda:0\",\n",
    "            dtype=torch.bfloat16,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "\n",
    "        self.model.eval() \n",
    "\n",
    "    @torch.no_grad()\n",
    "    def process_batch_(self, batch_items):        \n",
    "        texts = [item[\"prompt\"] for item in batch_items]\n",
    "        videos = [item[\"frames\"] for item in batch_items]\n",
    "        \n",
    "        inputs = self.processor(text=texts, videos=videos, padding=True, return_tensors=\"pt\")\n",
    "        inputs = inputs.to(\"cuda:0\")\n",
    "\n",
    "        output_ids = self.model.generate(**inputs, max_new_tokens=40, min_new_tokens=5)\n",
    "        output_ids = [out_ids[len(in_ids):] for in_ids, out_ids in zip(inputs.input_ids, output_ids)]\n",
    "        output_texts = self.processor.batch_decode(output_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)\n",
    "        \n",
    "        return output_texts\n",
    "    \n",
    "    def generate_captions(self, dataloader):     \n",
    "        results = []\n",
    "\n",
    "        for batch in tqdm(dataloader):\n",
    "            captions = self.process_batch_(batch)\n",
    "            for i, item in enumerate(batch):\n",
    "                results.append({\n",
    "                    \"video_path\": item[\"video_path\"],\n",
    "                    \"generated_caption\": captions[i]\n",
    "                })\n",
    "                \n",
    "        return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T20:46:25.491908Z",
     "iopub.status.busy": "2025-12-16T20:46:25.491359Z",
     "iopub.status.idle": "2025-12-16T20:46:30.079245Z",
     "shell.execute_reply": "2025-12-16T20:46:30.078467Z",
     "shell.execute_reply.started": "2025-12-16T20:46:25.491881Z"
    }
   },
   "outputs": [],
   "source": [
    "df = download_msrvtt_dataset(\"MSRVTT_videos\", 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-16T20:54:41.503835Z",
     "iopub.status.busy": "2025-12-16T20:54:41.503158Z",
     "iopub.status.idle": "2025-12-16T20:54:49.734225Z",
     "shell.execute_reply": "2025-12-16T20:54:49.733624Z",
     "shell.execute_reply.started": "2025-12-16T20:54:41.503812Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline = CaptionGenerationPipeline()\n",
    "dataset = VideoDataset(df, pipeline.processor)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-12-16T10:52:24.686899Z",
     "iopub.status.idle": "2025-12-16T10:52:24.687126Z",
     "shell.execute_reply": "2025-12-16T10:52:24.687032Z",
     "shell.execute_reply.started": "2025-12-16T10:52:24.687022Z"
    }
   },
   "outputs": [],
   "source": [
    "results = pipeline.generate_captions(dataloader)\n",
    "\n",
    "with open(\"msrvtt_captions.pkl\", 'wb') as f:\n",
    "    pickle.dump(results, f)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
